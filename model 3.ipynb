{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14afdba7",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44b12b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from IPython.display import HTML\n",
    "from scipy.sparse import coo_matrix, csc_matrix, csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a310edf6",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78730fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "books_df = pd.read_csv(\"data/books_data.csv\")\n",
    "reviews_df = pd.read_csv(\"data/books_rating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d51dcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_reviews_df(reviews_df):\n",
    "    \"\"\"\n",
    "    This function preprocesses the reviews dataframe\n",
    "\n",
    "        Args:\n",
    "            reviews_df (pd.DataFrame): dataframe of the original reviews\n",
    "\n",
    "        Returns:\n",
    "            reviews_df (pd.DataFrame): preprocessed dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # rename columns for consistency\n",
    "    reviews_df.rename(\n",
    "        columns={\n",
    "            \"Id\": \"book_id\",\n",
    "            \"Title\": \"title\",\n",
    "            \"Price\": \"price\",\n",
    "            \"User_id\": \"user_id\",\n",
    "            \"profileName\": \"profile_name\",\n",
    "            \"review/helpfulness\": \"helpfulness\",\n",
    "            \"review/score\": \"score\",\n",
    "            \"review/time\": \"review_date\",\n",
    "            \"review/summary\": \"summary\",\n",
    "            \"review/text\": \"text\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    # get the year of the review from the date (review/time)\n",
    "    reviews_df[\"year\"] = reviews_df[\"review_date\"].apply(\n",
    "        lambda x: datetime.utcfromtimestamp(x).year\n",
    "    )\n",
    "\n",
    "    # drop unnecessary cols\n",
    "    reviews_df.drop(columns=[\"price\"], inplace=True)\n",
    "\n",
    "    # drop the null titles and users\n",
    "    reviews_df = reviews_df.dropna(subset=[\"title\", \"user_id\"])\n",
    "\n",
    "    # Preprocess helpfulness\n",
    "    # handle 0/0\n",
    "    reviews_df[\"helpfulness\"] = reviews_df[\"helpfulness\"].replace(\"0/0\", 0)\n",
    "\n",
    "    # convert each helpfulness string to float\n",
    "    reviews_df[\"helpfulness\"] = reviews_df[\"helpfulness\"].apply(\n",
    "        lambda x: eval(x) if isinstance(x, str) and \"/\" in x else x\n",
    "    )\n",
    "    reviews_df[\"helpfulness\"] = reviews_df[\"helpfulness\"].astype(float)\n",
    "    reviews_df[\"helpfulness\"]\n",
    "\n",
    "    # drop duplicate reviews\n",
    "    reviews_df.drop_duplicates(\n",
    "        subset=[\"user_id\", \"score\", \"review_date\", \"summary\", \"text\"], inplace=True\n",
    "    )\n",
    "\n",
    "    return reviews_df\n",
    "\n",
    "\n",
    "def preprocess_books_df(books_df):\n",
    "    # drop irrelevant cols\n",
    "    books_df.drop(\n",
    "        columns=[\"previewLink\", \"infoLink\", \"ratingsCount\", \"publisher\"], inplace=True\n",
    "    )\n",
    "\n",
    "    # rename cols\n",
    "    books_df.rename(\n",
    "        columns={\n",
    "            \"Title\": \"title\",\n",
    "            \"publishedDate\": \"published_date\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    # drop null values in Title\n",
    "    books_df.dropna(subset=[\"title\"], inplace=True)\n",
    "\n",
    "    # fix the dates, extract the year of the book\n",
    "    books_df[\"published_date\"] = books_df[\"published_date\"].replace(\"1963*\", 1963)\n",
    "    books_df[\"published_date\"] = (\n",
    "        books_df[\"published_date\"].astype(str).str.extract(r\"(\\d{4})\")\n",
    "    )\n",
    "    books_df[\"published_date\"] = books_df[\"published_date\"].apply(\n",
    "        lambda x: int(x) if isinstance(x, str) and x.isdigit() else x\n",
    "    )\n",
    "\n",
    "    # calculate age (recency feature) - possibly for content based filtering if combined with category for ex\n",
    "    books_df[\"age\"] = datetime.today().year - books_df[\"published_date\"]\n",
    "\n",
    "    return books_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73afc551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\insiy\\AppData\\Local\\Temp\\ipykernel_11136\\121586150.py:31: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  lambda x: datetime.utcfromtimestamp(x).year\n",
      "C:\\Users\\insiy\\AppData\\Local\\Temp\\ipykernel_11136\\121586150.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reviews_df[\"helpfulness\"] = reviews_df[\"helpfulness\"].replace(\"0/0\", 0)\n",
      "C:\\Users\\insiy\\AppData\\Local\\Temp\\ipykernel_11136\\121586150.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reviews_df[\"helpfulness\"] = reviews_df[\"helpfulness\"].apply(\n",
      "C:\\Users\\insiy\\AppData\\Local\\Temp\\ipykernel_11136\\121586150.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reviews_df[\"helpfulness\"] = reviews_df[\"helpfulness\"].astype(float)\n",
      "C:\\Users\\insiy\\AppData\\Local\\Temp\\ipykernel_11136\\121586150.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reviews_df.drop_duplicates(\n"
     ]
    }
   ],
   "source": [
    "reviews_df = preprocess_reviews_df(reviews_df)\n",
    "books_df = preprocess_books_df(books_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3942e347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_review_counts(books_df):\n",
    "    # calculate review count for each book\n",
    "    review_counts_dict = (\n",
    "        reviews_df.groupby(\"title\").agg(count=(\"book_id\", \"count\")).to_dict()[\"count\"]\n",
    "    )\n",
    "\n",
    "    # add the count column to books_df\n",
    "    books_df[\"count\"] = books_df[\"title\"].apply(lambda x: review_counts_dict.get(x))\n",
    "\n",
    "    books_df.sort_values(by=\"count\", ascending=False)\n",
    "\n",
    "    return books_df\n",
    "\n",
    "\n",
    "books_df = calc_review_counts(books_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c797859f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "      <th>profile_name</th>\n",
       "      <th>helpfulness</th>\n",
       "      <th>score</th>\n",
       "      <th>review_date</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1882931173</td>\n",
       "      <td>Its Only Art If Its Well Hung!</td>\n",
       "      <td>AVCGYZL8FQQTD</td>\n",
       "      <td>Jim of Oz \"jim-of-oz\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>940636800</td>\n",
       "      <td>Nice collection of Julie Strain images</td>\n",
       "      <td>This is only for Julie Strain fans. It's a col...</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>A30TK6U7DNS82R</td>\n",
       "      <td>Kevin Killian</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1095724800</td>\n",
       "      <td>Really Enjoyed It</td>\n",
       "      <td>I don't care much for Dr. Seuss but after read...</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>A3UH4UZ4RSVO82</td>\n",
       "      <td>John Granger</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1078790400</td>\n",
       "      <td>Essential for every personal and Public Library</td>\n",
       "      <td>If people become the books they read and if \"t...</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>A2MVUWT453QH61</td>\n",
       "      <td>Roy E. Perry \"amateur philosopher\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1090713600</td>\n",
       "      <td>Phlip Nel gives silly Seuss a serious treatment</td>\n",
       "      <td>Theodore Seuss Geisel (1904-1991), aka &amp;quot;D...</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>A22X4XUPKF66MR</td>\n",
       "      <td>D. H. Richards \"ninthwavestore\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1107993600</td>\n",
       "      <td>Good academic overview</td>\n",
       "      <td>Philip Nel - Dr. Seuss: American IconThis is b...</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      book_id                           title         user_id  \\\n",
       "0  1882931173  Its Only Art If Its Well Hung!   AVCGYZL8FQQTD   \n",
       "1  0826414346        Dr. Seuss: American Icon  A30TK6U7DNS82R   \n",
       "2  0826414346        Dr. Seuss: American Icon  A3UH4UZ4RSVO82   \n",
       "3  0826414346        Dr. Seuss: American Icon  A2MVUWT453QH61   \n",
       "4  0826414346        Dr. Seuss: American Icon  A22X4XUPKF66MR   \n",
       "\n",
       "                         profile_name  helpfulness  score  review_date  \\\n",
       "0               Jim of Oz \"jim-of-oz\"     1.000000    4.0    940636800   \n",
       "1                       Kevin Killian     1.000000    5.0   1095724800   \n",
       "2                        John Granger     0.909091    5.0   1078790400   \n",
       "3  Roy E. Perry \"amateur philosopher\"     1.000000    4.0   1090713600   \n",
       "4     D. H. Richards \"ninthwavestore\"     1.000000    4.0   1107993600   \n",
       "\n",
       "                                           summary  \\\n",
       "0           Nice collection of Julie Strain images   \n",
       "1                                Really Enjoyed It   \n",
       "2  Essential for every personal and Public Library   \n",
       "3  Phlip Nel gives silly Seuss a serious treatment   \n",
       "4                           Good academic overview   \n",
       "\n",
       "                                                text  year  \n",
       "0  This is only for Julie Strain fans. It's a col...  1999  \n",
       "1  I don't care much for Dr. Seuss but after read...  2004  \n",
       "2  If people become the books they read and if \"t...  2004  \n",
       "3  Theodore Seuss Geisel (1904-1991), aka &quot;D...  2004  \n",
       "4  Philip Nel - Dr. Seuss: American IconThis is b...  2005  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fcd3daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>authors</th>\n",
       "      <th>image</th>\n",
       "      <th>published_date</th>\n",
       "      <th>categories</th>\n",
       "      <th>age</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Its Only Art If Its Well Hung!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Julie Strain']</td>\n",
       "      <td>http://books.google.com/books/content?id=DykPA...</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>['Comics &amp; Graphic Novels']</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>Philip Nel takes a fascinating look into the k...</td>\n",
       "      <td>['Philip Nel']</td>\n",
       "      <td>http://books.google.com/books/content?id=IjvHQ...</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wonderful Worship in Smaller Churches</td>\n",
       "      <td>This resource includes twelve principles in un...</td>\n",
       "      <td>['David R. Ray']</td>\n",
       "      <td>http://books.google.com/books/content?id=2tsDA...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>['Religion']</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Whispers of the Wicked Saints</td>\n",
       "      <td>Julia Thomas finds her life spinning out of co...</td>\n",
       "      <td>['Veronica Haddon']</td>\n",
       "      <td>http://books.google.com/books/content?id=aRSIg...</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>['Fiction']</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nation Dance: Religion, Identity and Cultural ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Edward Long']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                     Its Only Art If Its Well Hung!   \n",
       "1                           Dr. Seuss: American Icon   \n",
       "2              Wonderful Worship in Smaller Churches   \n",
       "3                      Whispers of the Wicked Saints   \n",
       "4  Nation Dance: Religion, Identity and Cultural ...   \n",
       "\n",
       "                                         description              authors  \\\n",
       "0                                                NaN     ['Julie Strain']   \n",
       "1  Philip Nel takes a fascinating look into the k...       ['Philip Nel']   \n",
       "2  This resource includes twelve principles in un...     ['David R. Ray']   \n",
       "3  Julia Thomas finds her life spinning out of co...  ['Veronica Haddon']   \n",
       "4                                                NaN      ['Edward Long']   \n",
       "\n",
       "                                               image  published_date  \\\n",
       "0  http://books.google.com/books/content?id=DykPA...          1996.0   \n",
       "1  http://books.google.com/books/content?id=IjvHQ...          2005.0   \n",
       "2  http://books.google.com/books/content?id=2tsDA...          2000.0   \n",
       "3  http://books.google.com/books/content?id=aRSIg...          2005.0   \n",
       "4                                                NaN          2003.0   \n",
       "\n",
       "                      categories   age  count  \n",
       "0    ['Comics & Graphic Novels']  29.0    1.0  \n",
       "1  ['Biography & Autobiography']  20.0    9.0  \n",
       "2                   ['Religion']  25.0    4.0  \n",
       "3                    ['Fiction']  20.0   32.0  \n",
       "4                            NaN  22.0    1.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6131fa3",
   "metadata": {},
   "source": [
    "# Non-personalized Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a386ed2",
   "metadata": {},
   "source": [
    "## Weighted Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fec786a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dfdbe19",
   "metadata": {},
   "source": [
    "## Bayesian Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b674d3e3",
   "metadata": {},
   "source": [
    "Note: function used from \"Non_Personalized_Recommendations_Trending_Now\" notebook from iLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aee65d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_scoring(reviews_df):\n",
    "    # step 1: create array with title, average rating of each book, and # of ratings\n",
    "    books_avg_ratings = (\n",
    "        reviews_df.groupby([\"title\"])\n",
    "        .agg(avg_rating=(\"score\", \"mean\"), num_ratings=(\"score\", \"count\"))\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # step 2: find m= Global average rating across all books\n",
    "    m = reviews_df[\"score\"].mean()\n",
    "    # step 3: find C= confidence factor\n",
    "    C = reviews_df[\"title\"].value_counts().mean()\n",
    "    # step 4: bayesian score\n",
    "    books_avg_ratings[\"bayesian_score\"] = (\n",
    "        C * m + books_avg_ratings[\"num_ratings\"] * books_avg_ratings[\"avg_rating\"]\n",
    "    ) / (C + books_avg_ratings[\"num_ratings\"])\n",
    "    # step 5: rank the movies based on their bayesian score\n",
    "    books_avg_ratings_ranked = books_avg_ratings.sort_values(\n",
    "        by=[\"bayesian_score\"], ascending=False\n",
    "    )\n",
    "    return books_avg_ratings_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c580318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 Books based on Bayesian Scoring Ranking\n",
    "top5 = bayesian_scoring(reviews_df).iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a7786f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_books_with_covers(df, title_col=\"title\", n=5):\n",
    "    \"\"\"\n",
    "    show the top books with cover\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): dataframe of the top books\n",
    "            title_col (str, optional): column name that contain book titles. Default = 'title'.\n",
    "            n (int, optional): no. of books to display. Default = 5.\n",
    "\n",
    "        Returns:\n",
    "            IPython.display.HTML: An HTML table with book covers and titles\n",
    "\n",
    "\n",
    "    Note: function and HTML is a refined version of -> https://github.com/masao/google_books_api_wrapper\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def get_google_books_cover(title):\n",
    "        url = f\"https://www.googleapis.com/books/v1/volumes?q=intitle:{title}\"\n",
    "        try:\n",
    "            response = requests.get(url, timeout=5).json()\n",
    "            return response[\"items\"][0][\"volumeInfo\"][\"imageLinks\"][\"thumbnail\"]\n",
    "        except Exception:\n",
    "            return \"https://via.placeholder.com/60x90?text=No+Cover\"\n",
    "\n",
    "    top_books = df.head(n).copy()\n",
    "    top_books[\"cover_url\"] = top_books[title_col].apply(get_google_books_cover)\n",
    "\n",
    "    # Build HTML table\n",
    "    html_table = [\n",
    "        \"<table style='border-collapse: collapse; text-align: left;'>\",\n",
    "        \"<tr><th>Cover</th><th>Title</th></tr>\",\n",
    "    ]\n",
    "    for _, row in top_books.iterrows():\n",
    "        html_table.append(\n",
    "            f\"<tr style='border: 1px solid #ccc;'>\"\n",
    "            f\"<td><img src='{row['cover_url']}' width='60'></td>\"\n",
    "            f\"<td style='padding: 8px;'>{row[title_col]}</td>\"\n",
    "            f\"</tr>\"\n",
    "        )\n",
    "    html_table.append(\"</table>\")\n",
    "\n",
    "    return HTML(\"\".join(html_table))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b9763cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style='border-collapse: collapse; text-align: left;'><tr><th>Cover</th><th>Title</th></tr><tr style='border: 1px solid #ccc;'><td><img src='http://books.google.com/books/content?id=YkVfeN-xC8wC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api' width='60'></td><td style='padding: 8px;'>Lilla Belle: The First Stages</td></tr><tr style='border: 1px solid #ccc;'><td><img src='https://via.placeholder.com/60x90?text=No+Cover' width='60'></td><td style='padding: 8px;'>the lion's paw</td></tr><tr style='border: 1px solid #ccc;'><td><img src='http://books.google.com/books/content?id=uFm6EAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api' width='60'></td><td style='padding: 8px;'>The Ferret Calendar 2005, Ferret Music</td></tr><tr style='border: 1px solid #ccc;'><td><img src='http://books.google.com/books/content?id=kfgnHCLvQPcC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api' width='60'></td><td style='padding: 8px;'>With the Old Breed: At Peleliu and Okinawa</td></tr><tr style='border: 1px solid #ccc;'><td><img src='http://books.google.com/books/content?id=BdZRmQEACAAJ&printsec=frontcover&img=1&zoom=1&source=gbs_api' width='60'></td><td style='padding: 8px;'>The Wealthy Spirit: Daily Affirmations for Financial Stress Reduction</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_top_books_with_covers(top5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff6b2c6",
   "metadata": {},
   "source": [
    "## Wilson Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19265191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edaa6740",
   "metadata": {},
   "source": [
    "## Apriori Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2518b552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8974c7f2",
   "metadata": {},
   "source": [
    "## FP Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a35f07d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5ef0df5",
   "metadata": {},
   "source": [
    "# Personalized Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc86d11",
   "metadata": {},
   "source": [
    "## User-based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa8b806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8eaafcf1",
   "metadata": {},
   "source": [
    "## Item-based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b5ee23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1693626, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_cols = [\"title\", \"user_id\", \"score\", \"review_date\"]\n",
    "user_book_reviews = reviews_df[relevant_cols]\n",
    "user_book_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e62fea07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(642291, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "      <th>score</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>A30TK6U7DNS82R</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1095724800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>A3UH4UZ4RSVO82</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1078790400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>A2MVUWT453QH61</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1090713600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>A22X4XUPKF66MR</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1107993600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>A2F6NONFUDB6UK</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1127174400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title         user_id  score  review_date\n",
       "1  Dr. Seuss: American Icon  A30TK6U7DNS82R    5.0   1095724800\n",
       "2  Dr. Seuss: American Icon  A3UH4UZ4RSVO82    5.0   1078790400\n",
       "3  Dr. Seuss: American Icon  A2MVUWT453QH61    4.0   1090713600\n",
       "4  Dr. Seuss: American Icon  A22X4XUPKF66MR    4.0   1107993600\n",
       "5  Dr. Seuss: American Icon  A2F6NONFUDB6UK    4.0   1127174400"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the 100k most active users and 100k most reviewed items\n",
    "most_active_users = user_book_reviews.user_id.value_counts().keys()[:100000]\n",
    "most_reviewed_books = user_book_reviews.title.value_counts().keys()[:100000]\n",
    "\n",
    "subset_reviews = user_book_reviews[\n",
    "    (user_book_reviews.user_id.isin(most_active_users))\n",
    "    & (user_book_reviews.title.isin(most_reviewed_books))\n",
    "]\n",
    "\n",
    "print(subset_reviews.shape)\n",
    "subset_reviews.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979ac059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the entire dataset\n",
    "subset_reviews = user_book_reviews\n",
    "\n",
    "\n",
    "rows = subset_reviews[\"user_id\"].astype(\"category\")\n",
    "cols = subset_reviews[\"title\"].astype(\"category\")\n",
    "\n",
    "user_mapping = rows.cat.categories\n",
    "book_mapping = cols.cat.categories\n",
    "\n",
    "sparse_matrix = csr_matrix((subset_reviews[\"score\"], (rows.cat.codes, cols.cat.codes)))\n",
    "# Renaming sparse_matrix to user_item_rating\n",
    "user_item_rating = sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35ee278a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 176927)\t5.0\n",
      "  (1, 163001)\t5.0\n",
      "  (2, 7687)\t3.0\n",
      "  (2, 163845)\t5.0\n",
      "  (3, 135363)\t5.0\n",
      "  (4, 141878)\t5.0\n",
      "  (5, 70522)\t5.0\n",
      "  (6, 139754)\t3.0\n",
      "  (7, 28314)\t5.0\n",
      "  (8, 143398)\t5.0\n",
      "  (9, 41399)\t5.0\n",
      "  (9, 130366)\t5.0\n",
      "  (9, 191001)\t4.0\n",
      "  (10, 170546)\t5.0\n",
      "  (11, 39433)\t4.0\n",
      "  (12, 20951)\t5.0\n",
      "  (13, 22203)\t4.0\n",
      "  (14, 36023)\t3.0\n",
      "  (15, 64763)\t5.0\n",
      "  (16, 153281)\t5.0\n",
      "  (17, 72640)\t5.0\n",
      "  (18, 135871)\t5.0\n",
      "  (19, 57044)\t3.0\n",
      "  (20, 141314)\t3.0\n",
      "  (21, 167697)\t5.0\n",
      "  :\t:\n",
      "  (1008942, 23216)\t5.0\n",
      "  (1008942, 143168)\t5.0\n",
      "  (1008943, 158562)\t4.0\n",
      "  (1008943, 168950)\t1.0\n",
      "  (1008944, 37349)\t5.0\n",
      "  (1008945, 136517)\t5.0\n",
      "  (1008946, 163038)\t5.0\n",
      "  (1008947, 14097)\t5.0\n",
      "  (1008948, 3090)\t2.0\n",
      "  (1008949, 145544)\t5.0\n",
      "  (1008950, 37019)\t1.0\n",
      "  (1008951, 106940)\t3.0\n",
      "  (1008952, 133839)\t4.0\n",
      "  (1008953, 166359)\t4.0\n",
      "  (1008954, 22045)\t5.0\n",
      "  (1008955, 35047)\t5.0\n",
      "  (1008956, 159326)\t5.0\n",
      "  (1008957, 120497)\t5.0\n",
      "  (1008958, 95150)\t5.0\n",
      "  (1008958, 105437)\t5.0\n",
      "  (1008958, 110187)\t5.0\n",
      "  (1008958, 136756)\t5.0\n",
      "  (1008958, 168068)\t5.0\n",
      "  (1008959, 106868)\t5.0\n",
      "  (1008960, 169199)\t5.0\n"
     ]
    }
   ],
   "source": [
    "print(user_item_rating.tocoo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895f5a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195986638406"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculates the total possible number of user-item interactions -> max number of entries matrix could have\n",
    "user_book_reviews.user_id.nunique() * user_book_reviews.title.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c635a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1679121"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns the number of non-zero entries in the sparse matrix.\n",
    "sparse_matrix.getnnz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f435a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mean for each item & user\n",
    "def get_avg(sparse_matrix, _axis):\n",
    "    # .A1 converts the sparse matrix result into a flat NumPy array.\n",
    "    sums = sparse_matrix.sum(axis=_axis).A1  # sum of only non-zero entries\n",
    "    counts = sparse_matrix.getnnz(axis=_axis)\n",
    "    AVG = sums / counts\n",
    "    return AVG\n",
    "\n",
    "\n",
    "# Find users who rated both book i and book j.\n",
    "def find_common_users(book_i_ratings, book_j_ratings):\n",
    "    i_j_common_users = set(book_i_ratings.row) & set(book_j_ratings.row)\n",
    "    i_j_common_users = np.array(list(i_j_common_users), dtype=book_i_ratings.row.dtype)\n",
    "    return i_j_common_users\n",
    "\n",
    "\n",
    "# Take rating vectors for book i and book j and keep only the ratings from common users.\n",
    "def filter_for_common_users(common_users, book_i_ratings, book_j_ratings):\n",
    "    # only get the ratings for the common users\n",
    "    mask = np.isin(book_i_ratings.tocoo().row, common_users)\n",
    "    book_i_ratings_filtered = book_i_ratings.tocoo().__class__(\n",
    "        (\n",
    "            book_i_ratings.tocoo().data[mask],\n",
    "            (book_i_ratings.tocoo().row[mask], book_i_ratings.tocoo().col[mask]),\n",
    "        ),\n",
    "        shape=book_i_ratings.tocoo().shape,\n",
    "    )\n",
    "\n",
    "    mask = np.isin(book_j_ratings.tocoo().row, common_users)\n",
    "    book_j_ratings_filtered = book_j_ratings.tocoo().__class__(\n",
    "        (\n",
    "            book_j_ratings.tocoo().data[mask],\n",
    "            (book_j_ratings.tocoo().row[mask], book_j_ratings.tocoo().col[mask]),\n",
    "        ),\n",
    "        shape=book_j_ratings.tocoo().shape,\n",
    "    )\n",
    "\n",
    "    return book_i_ratings_filtered, book_j_ratings_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4029c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of common users for each pair\n",
    "coo = sparse_matrix.tocoo()\n",
    "# This keeps the same structure but replaces ratings with 1.\n",
    "binary = coo.copy()\n",
    "binary.data = np.ones_like(binary.data)\n",
    "# Compute overlap between books\n",
    "book_pairs_to_common_users = binary.T.dot(binary)\n",
    "\n",
    "# filter for pairs with #common_users > N\n",
    "coo_pairs = book_pairs_to_common_users.tocoo()\n",
    "N = 5\n",
    "mask = coo_pairs.data >= N\n",
    "book_pairs_to_common_users_filtered = coo_pairs.__class__(\n",
    "    (coo_pairs.data[mask], (coo_pairs.row[mask], coo_pairs.col[mask])),\n",
    "    shape=coo_pairs.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b58a23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 174618)\t1.0\n",
      "  (0, 172974)\t1.0\n",
      "  (0, 165841)\t1.0\n",
      "  (0, 165634)\t1.0\n",
      "  (0, 157157)\t1.0\n",
      "  (0, 150063)\t1.0\n",
      "  (0, 139856)\t1.0\n",
      "  (0, 125616)\t1.0\n",
      "  (0, 111457)\t1.0\n",
      "  (0, 105150)\t1.0\n",
      "  (0, 104275)\t1.0\n",
      "  (0, 38314)\t1.0\n",
      "  (0, 38039)\t1.0\n",
      "  (0, 0)\t2.0\n",
      "  (1, 184835)\t1.0\n",
      "  (1, 36869)\t1.0\n",
      "  (1, 10202)\t1.0\n",
      "  (1, 1224)\t1.0\n",
      "  (1, 194117)\t1.0\n",
      "  (1, 188481)\t1.0\n",
      "  (1, 181425)\t1.0\n",
      "  (1, 180623)\t1.0\n",
      "  (1, 180397)\t1.0\n",
      "  (1, 178660)\t1.0\n",
      "  (1, 174908)\t1.0\n",
      "  :\t:\n",
      "  (194242, 174938)\t1.0\n",
      "  (194242, 17426)\t1.0\n",
      "  (194242, 169344)\t1.0\n",
      "  (194242, 165846)\t1.0\n",
      "  (194242, 161471)\t1.0\n",
      "  (194242, 157067)\t1.0\n",
      "  (194242, 137761)\t1.0\n",
      "  (194242, 136340)\t1.0\n",
      "  (194242, 118535)\t1.0\n",
      "  (194242, 101592)\t1.0\n",
      "  (194242, 91836)\t1.0\n",
      "  (194242, 84247)\t1.0\n",
      "  (194242, 79233)\t1.0\n",
      "  (194242, 76631)\t1.0\n",
      "  (194242, 51936)\t1.0\n",
      "  (194242, 46366)\t1.0\n",
      "  (194242, 39683)\t1.0\n",
      "  (194242, 27210)\t2.0\n",
      "  (194242, 13299)\t1.0\n",
      "  (194242, 12749)\t1.0\n",
      "  (194242, 11206)\t1.0\n",
      "  (194242, 194242)\t19.0\n",
      "  (194243, 194243)\t1.0\n",
      "  (194244, 194244)\t2.0\n",
      "  (194245, 194245)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(book_pairs_to_common_users.tocoo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b4a16c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_AVGS = get_avg(sparse_matrix, _axis=1)\n",
    "BOOKS_AVGS = get_avg(sparse_matrix, _axis=0)\n",
    "\n",
    "# adjust the rating for each item vector v to be (v - user_avg)\n",
    "user_book_to_rating_adjusted = sparse_matrix.copy()\n",
    "coo = user_book_to_rating_adjusted.tocoo()\n",
    "coo.data = coo.data - USER_AVGS[coo.row]\n",
    "user_book_to_rating_adjusted.data = coo.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dfc8878f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 176927)\t0.0\n",
      "  (1, 163001)\t0.0\n",
      "  (2, 7687)\t-1.0\n",
      "  (2, 163845)\t1.0\n",
      "  (3, 135363)\t0.0\n",
      "  (4, 141878)\t0.0\n",
      "  (5, 70522)\t0.0\n",
      "  (6, 139754)\t0.0\n",
      "  (7, 28314)\t0.0\n",
      "  (8, 143398)\t0.0\n",
      "  (9, 41399)\t0.33333333333333304\n",
      "  (9, 130366)\t0.33333333333333304\n",
      "  (9, 191001)\t-0.666666666666667\n",
      "  (10, 170546)\t0.0\n",
      "  (11, 39433)\t0.0\n",
      "  (12, 20951)\t0.0\n",
      "  (13, 22203)\t0.0\n",
      "  (14, 36023)\t0.0\n",
      "  (15, 64763)\t0.0\n",
      "  (16, 153281)\t0.0\n",
      "  (17, 72640)\t0.0\n",
      "  (18, 135871)\t0.0\n",
      "  (19, 57044)\t0.0\n",
      "  (20, 141314)\t0.0\n",
      "  (21, 167697)\t0.0\n",
      "  :\t:\n",
      "  (1008942, 23216)\t0.0\n",
      "  (1008942, 143168)\t0.0\n",
      "  (1008943, 158562)\t1.5\n",
      "  (1008943, 168950)\t-1.5\n",
      "  (1008944, 37349)\t0.0\n",
      "  (1008945, 136517)\t0.0\n",
      "  (1008946, 163038)\t0.0\n",
      "  (1008947, 14097)\t0.0\n",
      "  (1008948, 3090)\t0.0\n",
      "  (1008949, 145544)\t0.0\n",
      "  (1008950, 37019)\t0.0\n",
      "  (1008951, 106940)\t0.0\n",
      "  (1008952, 133839)\t0.0\n",
      "  (1008953, 166359)\t0.0\n",
      "  (1008954, 22045)\t0.0\n",
      "  (1008955, 35047)\t0.0\n",
      "  (1008956, 159326)\t0.0\n",
      "  (1008957, 120497)\t0.0\n",
      "  (1008958, 95150)\t0.0\n",
      "  (1008958, 105437)\t0.0\n",
      "  (1008958, 110187)\t0.0\n",
      "  (1008958, 136756)\t0.0\n",
      "  (1008958, 168068)\t0.0\n",
      "  (1008959, 106868)\t0.0\n",
      "  (1008960, 169199)\t0.0\n"
     ]
    }
   ],
   "source": [
    "print(user_book_to_rating_adjusted.tocoo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f685e0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for each item pair, find the cosine similarity IF we have >N common users\\n\\n# Calculate item based similarity\\nsimilarity_map = {}\\n\\n# compute similarity\\nfor i, j in zip(\\n    book_pairs_to_common_users_filtered.row, book_pairs_to_common_users_filtered.col\\n):\\n    if (similarity_map.get(i, {}).get(j) is None) and (i != j):\\n        # book_i = cols.cat.categories[i]  # map index to actual book title\\n        # book_j = cols.cat.categories[j]  # map index to actual book title\\n        book_i_ratings = user_book_to_rating_adjusted[:, i].tocoo()\\n        book_j_ratings = user_book_to_rating_adjusted[:, j].tocoo()\\n\\n        i_j_common_users = find_common_users(book_i_ratings, book_j_ratings)\\n\\n        # filter to get ratings for common users only\\n        book_i_ratings_filtered, book_j_ratings_filtered = filter_for_common_users(\\n            i_j_common_users, book_i_ratings, book_j_ratings\\n        )\\n\\n        # compute the dot product\\n        dot = book_j_ratings_filtered.data.dot(book_i_ratings_filtered.data)\\n        norm_i = np.linalg.norm(book_i_ratings_filtered.data)\\n        norm_j = np.linalg.norm(book_j_ratings_filtered.data)\\n        cos_sim = dot / (norm_i * norm_j)\\n\\n        if i not in similarity_map:\\n            similarity_map[i] = {}\\n        if j not in similarity_map:\\n            similarity_map[j] = {}\\n\\n        similarity_map[i][j] = cos_sim\\n        similarity_map[j][i] = cos_sim\\n\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for each item pair, find the cosine similarity IF we have >N common users\n",
    "\n",
    "# Calculate item based similarity\n",
    "similarity_map = {}\n",
    "\n",
    "# compute similarity\n",
    "for i, j in zip(\n",
    "    book_pairs_to_common_users_filtered.row, book_pairs_to_common_users_filtered.col\n",
    "):\n",
    "    if (similarity_map.get(i, {}).get(j) is None) and (i != j):\n",
    "        # book_i = cols.cat.categories[i]  # map index to actual book title\n",
    "        # book_j = cols.cat.categories[j]  # map index to actual book title\n",
    "        book_i_ratings = user_book_to_rating_adjusted[:, i].tocoo()\n",
    "        book_j_ratings = user_book_to_rating_adjusted[:, j].tocoo()\n",
    "\n",
    "        i_j_common_users = find_common_users(book_i_ratings, book_j_ratings)\n",
    "\n",
    "        # filter to get ratings for common users only\n",
    "        book_i_ratings_filtered, book_j_ratings_filtered = filter_for_common_users(\n",
    "            i_j_common_users, book_i_ratings, book_j_ratings\n",
    "        )\n",
    "\n",
    "        # compute the dot product\n",
    "        dot = book_j_ratings_filtered.data.dot(book_i_ratings_filtered.data)\n",
    "        norm_i = np.linalg.norm(book_i_ratings_filtered.data)\n",
    "        norm_j = np.linalg.norm(book_j_ratings_filtered.data)\n",
    "        cos_sim = dot / (norm_i * norm_j)\n",
    "\n",
    "        if i not in similarity_map:\n",
    "            similarity_map[i] = {}\n",
    "        if j not in similarity_map:\n",
    "            similarity_map[j] = {}\n",
    "\n",
    "        similarity_map[i][j] = cos_sim\n",
    "        similarity_map[j][i] = cos_sim\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b143318",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# computes adjusted pairwise similarity between rows of X by default - thats why we are using transpose:\n",
    "similarity_matrix = cosine_similarity(\n",
    "    user_book_to_rating_adjusted.T, dense_output=False\n",
    ")\n",
    "\n",
    "# keep the similarities for only the books that have atleast N common users\n",
    "N = 5\n",
    "similarity_matrix = similarity_matrix.multiply(book_pairs_to_common_users >= N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85e2763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a given target user:\n",
    "# get the candidate books that can be recommended to the user:\n",
    "#   books the user did not rate and they exist in our sim map\n",
    "    # for the 3 best most recently rated book:\n",
    "    # get the sim score between it and each of the candidate books\n",
    "    # choose the k most similar books\n",
    "    # for the k most similar books, calculate the predicted rating\n",
    "    # recommend the 5 highest rated books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f233b8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure it's COO\n",
    "def get_k_neighbors(coo_mat, k):\n",
    "    coo = coo_mat.tocoo()\n",
    "\n",
    "    # Get indices of the top 3 values\n",
    "    topk_idx = np.argsort(np.abs(coo.data))[-k:][::-1]  # sort descending\n",
    "\n",
    "    # Get the corresponding row indices\n",
    "    topk_rows = coo.row[topk_idx]\n",
    "    topk_values = coo.data[topk_idx]\n",
    "\n",
    "    # print(\"Top 3 row indices:\", topk_rows)\n",
    "    # print(\"Top 3 values:\", topk_values)\n",
    "\n",
    "    return topk_rows, topk_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "778b43df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194243\n"
     ]
    }
   ],
   "source": [
    "# Assume user 0 is a target user\n",
    "\n",
    "target_user_id = \"AVCGYZL8FQQTD\"\n",
    "target_user_idx = user_mapping.get_loc(target_user_id)\n",
    "target_user = user_book_reviews[(user_book_reviews[\"user_id\"] == target_user_id)]\n",
    "target_mean = target_user[\"score\"].mean()\n",
    "\n",
    "\n",
    "# i want to recommend an unread book to this target user\n",
    "# get the candidate books (unread by the user)\n",
    "read_books_indices = [book_mapping.get_loc(t) for t in target_user.title]\n",
    "candidate_books = list(set(sparse_matrix.tocoo().col) - set(read_books_indices))\n",
    "print(len(candidate_books))\n",
    "\n",
    "# get all the books that the target read : read_books_indices\n",
    "# for each candidate book:\n",
    "    # get the similarity between the candidate book and the read books\n",
    "    # deviation for the read book: target user rating for read book - global avg for read book\n",
    "\n",
    "\n",
    "# if this candidate has similarity scores with other candidates, filter only for candidates in read_books_indices\n",
    "# i want to predict the rating for a candidate. i will filter the candidates for items that are in \n",
    "#items having sim score\n",
    "target_candidate_to_predict = 8 #in principal, you should predict ratings for all candidates\n",
    "items_having_sim_score_with_candidate = similarity_matrix[: , target_candidate_to_predict].tocoo().row     \n",
    "items_having_sim_score_with_candidate_and_target_read_them = set(items_having_sim_score_with_candidate) & set(read_books_indices)\n",
    "\n",
    "predicted_ratings = {}\n",
    "\n",
    "# Precompute user deviations once\n",
    "import time\n",
    "time_now = int(time.time())\n",
    "\n",
    "user_ratings = sparse_matrix[target_user_idx, read_books_indices].toarray().ravel()\n",
    "deviations = user_ratings - BOOKS_AVGS[read_books_indices] # what for ? \n",
    "\n",
    "time_of_rating_i = target_user.set_index(\"title\")[\"review_date\"]\n",
    "aligned_times = np.array([time_of_rating_i[book_mapping[i]] for i in read_books_indices])\n",
    "\n",
    "# for relevance, let t be a time decay factor = 1 / 1+0.5*(today - time)\n",
    "for cand in candidate_books:\n",
    "\n",
    "    # similarities of candidate c to the books user read\n",
    "    sim_col = similarity_matrix[read_books_indices, cand].toarray().ravel()\n",
    "    \n",
    "    \n",
    "    # TODO : choose the k neighbors \n",
    "    # TODO : Exploitation vs exploration - \n",
    "    #           say we have k = 3. \n",
    "    #           2 should have high sim scores like 0.9\n",
    "    #           1 should have sim between 0.6-0.9\n",
    "    # TODO : Optimize parameters\n",
    "    \n",
    "    # keep only similarities that are nonzero\n",
    "    mask = (sim_col != 0)\n",
    "    if not mask.any():\n",
    "        continue  # skip candidate if no similar items\n",
    "    \n",
    "    sim_col_ = sim_col[mask]\n",
    "    deviations_ = deviations[mask]\n",
    "    \n",
    "    taste_change_factor = 0.3 # can be optimized\n",
    "    time_factor = 1 / (1 + taste_change_factor * (time_now - aligned_times))\n",
    "    time_factor = time_factor[mask]\n",
    "\n",
    "    # predicted rating\n",
    "    #numerator = sim_col_ @ deviations_\n",
    "    numerator = (sim_col_ * deviations_ * time_factor).sum()\n",
    "    denominator = np.abs(sim_col_).sum()\n",
    "    pred_rating = BOOKS_AVGS[cand] + numerator/denominator\n",
    "\n",
    "    predicted_ratings[cand] = pred_rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9167a2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{19465: 4.29032258093371,\n",
       " 119641: 3.904761905050453,\n",
       " 153475: 3.7400000002885485}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a00dd7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_recent_title_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\" ignore for now \"\"\"\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[43mbest_recent_title_indices\u001b[49m:\n\u001b[0;32m      4\u001b[0m     target_col \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      5\u001b[0m         similarity_matrix[:, idx]\u001b[38;5;241m.\u001b[39mtocoo()\n\u001b[0;32m      6\u001b[0m     )  \u001b[38;5;66;03m# get the similarity scores between this book and all other books in the matrix\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mnp\u001b[38;5;241m.\u001b[39misin(target_col\u001b[38;5;241m.\u001b[39mrow, read_books_indices)  \u001b[38;5;66;03m# remove the read books\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_recent_title_indices' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\" ignore for now \"\"\"\n",
    "for idx in best_recent_title_indices:\n",
    "    \n",
    "    target_col = (\n",
    "        similarity_matrix[:, idx].tocoo()\n",
    "    )  # get the similarity scores between this book and all other books in the matrix\n",
    "\n",
    "    mask = ~np.isin(target_col.row, read_books_indices)  # remove the read books\n",
    "\n",
    "    target_candidate_similarities = coo_matrix(\n",
    "        (target_col.data[mask], (target_col.row[mask], target_col.col[mask])),\n",
    "        shape=similarity_matrix[:, idx].shape,\n",
    "    )\n",
    "\n",
    "    # check with Dr. Alex -- the candidates aren't all unread books, they're the unread books that exist in our similarity map\n",
    "    #print(target_candidate_similarities)\n",
    "\n",
    "    # get the k most similar books that the target user also rated: \n",
    "    #  check with insiyah, do i look at absolute sim score?\n",
    "    topk_rows, topk_values = get_k_neighbors(target_candidate_similarities, k=15)\n",
    "    \n",
    "    print(\n",
    "        f\"Top k similar movies for {book_mapping[idx]} : {book_mapping[topk_rows]}\"\n",
    "    )\n",
    "    print(\"Their similarity scores:\", topk_values)\n",
    "    print(\"--------------------------------------------\")\n",
    "    \n",
    "    # predict the rating for the k-most similar books\n",
    "    # so the neighbors have to be items that the target user also rated\n",
    "    # item avg + deviation: \n",
    "    #           how did this target user's ratings deviate from the sim items avgs\n",
    "    # deviation = sim_score_with_target*(target_user_rating - sim_item's_avg) \n",
    "    # numerator = sim_score * \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
